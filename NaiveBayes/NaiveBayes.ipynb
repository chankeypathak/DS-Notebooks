{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://shatterline.com/blog/2013/09/12/not-so-naive-classification-with-the-naive-bayes-classifier/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples in the above link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assumptions:<br>\n",
    "\n",
    "### Features must be independent so we can use<br>\n",
    "\n",
    "#### -> BOW<br>\n",
    "#### -> TFIDF<br>\n",
    "\n",
    "#### we cant use W2V and tfidf W2V as features are dependent in these techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applications: <br>\n",
    "-> Spam Filtering<br>\n",
    "-> Review Classififcation etc...<br>\n",
    "\n",
    "basically its most widely used for Text Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laplace/Additive Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "its used to avoide errors in probabilities i.e While calculating using Naive Bayes formula if we get probability as 0 in any part of the formula total value becomes zero to avoide this we add alpha in numerator and 2alpha in denominator so that value will not be zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Probabilities For numerical Stablization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just apply log for every part in Naive Bayes Formula to avoide very smaller values with larger precision. i.e we are dealing with the values between 0-1 python supports upto 16 decimal places if the calculation goes beyond it, it will round of to give error value to avoide this we use LOG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications / Note:\n",
    "It works well with data set where the Features are  independent but practically it works good even some features are dependent<br>\n",
    "\n",
    "It Works Well in Case of Text Based Classification.<br>\n",
    "\n",
    "Its most widely used with Catogorical Features.<br>\n",
    "\n",
    "Perform Laplace Smoothing so that our model works well<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
